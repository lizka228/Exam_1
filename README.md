# Exam_1
Экзамен Инжиниринг данных

# Название проекта:
Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow и облачного хранилища для датасета Breast Cancer Wisconsin Diagnostic.

# Содержание:
1. Цель проекта и описание данных
2. Архитектура пайплайна
3. Скрипты пайплайна
4. DAG
5. Интеграция с облачным хранилищем или локальным диском
6. Инструкция по запуску
8. Анализ ошибок и устойчивости
10. Скриншоты работающего DAG

# Цель проекта и описание данных
**Цель задания:** Спроектировать и реализовать автоматизированный ETL-процесс: от получения медицинских данных до выгрузки результатов модели в облачное хранилище с помощью Apache Airflow и Python. 

**Описание датасета:** датасет состоит из 32 колонок (без пропусков) находится в папке /data.
  1) Идентификационный номер
  2) Диагноз (М = злокачественный, В = доброкачественный)

(3-32) Для каждого ядра клетки вычисляются десять вещественных признаков:
  - радиус (среднее значение расстояний от центра до точек по периметру)
  - текстура (стандартное отклонение значений оттенков серого)
  - периметр
  - площадь
  - гладкость (локальное изменение длины радиуса)
  - компактность (периметр^2 / площадь - 1,0)
  - вогнутость (выраженность вогнутых участков контура)
  - вогнутые точки (количество вогнутых участков контура)
  - симметрия
  - фрактальная размерность ("приближение береговой линии" - 1)

Средняя, стандартная ошибка и «худшая» или наибольшая (среднее из трех наибольших значений) этих признаков были вычислены для каждого изображения, в результате чего получилось 30 признаков.

**ML-задача:** Разработать и обучить модель логистической регрессии, которая должна предсказывать, является опухоль злокачественной или доброкачественной на основе медицинских данных (задача бинарной классификации).

# Архитектура пайплайна
Пайплайн включает следующие этапы:
  - Загрузка данных - парсинг CSV
  - Предобработка - чистка, нормализация, обработка пропущенных значений, перевод целевого значения в 0 и 1
  - Обучение модели - разделение данных, обучение модели LogisticRegression на тренировочном наборе 
  - Оценка метрик - вычисление Accuracy, Precision, Recall, F1.
  - Сохранение результатов - модель и метрики выгружаются в облачное хранилище

Визуацизация в виде блок-схемы:

![diagram](https://github.com/user-attachments/assets/74914ceb-d12f-4c7f-a77f-d44c07e9b9ae)

# Скрипты пайплайна
Все скрипты для пайплайна находятся в папке /etl.
Связи между скриптами
1. load_data.py
    - Загружает Breast Cancer Wisconsin Diagnostic Dataset из CSV-файла.
    - Выполняет базовый анализ: проверяет пропущенные значения, типы данных и статистику.
    - Сохраняет предварительно обработанные данные.
2. preprocess.py
    - Убирает ненужные колонки (`id`).
    - Заполняет пропущенные значения.
    - Нормализует данные.
    - Преобразует таргет в бинарный вид (1 - злокачественная опухоль, 0 - доброкаественная)
3. train_model.py
    - Делит на признаки и таргет
    - Делит на тренировочкую (80%) и тестовую (20%) выборки
    - Обучает LogisticRegression на обработанных данных.
4. evaluate.py
    - Вычисляет Accuracy, Precision, Recall, F1-score.
5. save_results.py
    - Сохраняет метрики в JSON и модель в Pickle в папку results.

Все скрипты запускаются из Airflow DAG последовательно

# DAG
Название DAG - pipeline_dag.py находится в папке /dags. Этот **Airflow DAG** реализует автоматизированный пайплайн для предобработки данных, обучения модели **Logistic Regression**, её оценки и сохранения результатов.
Граф DAG:

![image](https://github.com/user-attachments/assets/34546867-a3b2-40f4-a8cb-71ce7638443e)

**Описание зависимостей:**

load_data - берёт путь из переменной окружения и загружает с помощью Pandas датасет, далее сохраняет в XCom как json для передачи следующей задаче.

preproccessing_data - забирает данные из XCom как json, убирает столбец с идентификатором, удаляет строки с nan, кодирует таргет в 0 и 1, стандартизирует числовые признаки и передаёт на следующий этап через XCom как json.

train_model - забирает данные из XCom как json, разделает на X и y, делит на тестовую и трейновую выборку, обучает модель логистической регрессии и передаёт модель через XCom как pickle, а X_test и y_test для следующего этапа оценки модели как json.

evaluaate_model - получает тестовые данные XCom как json и модель через XCom как pickle, считает Accuracy, Precision, Recall, F1-score, состаувляет словарь с метриками и передаёт на следующий этап через XCom.

save_results - получает метрики из XCom с предыдущего этапа и модель из XCom с этапа обучения, сохраняет результаты по путям, которые берёт из переменных окружения, если в переменной окружения указан токен яндекс диска, то туда тоже сохраняет результаты.

# Интеграция с облачным хранилищем или локальным диском
Загрузка данных реализована только через локальный диск. Для загрузки с локального диска необходимо указать полный путь к датасету (DATA_PATH в формате .csv) в файле .env (пример файла в репозитории).

В оркестрации реализована как выгрузка результатов работы на локальный диск, так и в облачное хранилище Яндекс диск. Для выгрузки на локальный диск необходимо указать полный путь с названием файла для модели (MODEL_PATH в формате .pkl) и для метрик (METRICS_PATH в формате .json) в файле .env (пример файла ниже). Для выгрузки на Яндекс диск в дополнение к вышеперечисленному необходимо указать OAth-токен (YADISK_TOKEN), а также папку, куда нужно загрузить (PAPKA) (инструкция: https://yandex.ru/dev/disk-api/doc/ru/concepts/quickstart#quickstart__oauth). Код пробует подключиться, после этого проверяет существование папки, если ёё нет, то создаёт и туда загружает результаты.

Пример .env:
<img width="408" alt="image" src="https://github.com/user-attachments/assets/58d2fbe5-bc82-4870-bfff-e607c528089d" />

# Инструкция по запуску
**Инструкцию по запуску DAG:**
 - Проверка наличия дага airflow dags list (Если ml_pipeline отсутствует в списке, нажно проверить в папке /dags файл .py)
![image](https://github.com/user-attachments/assets/b8747e22-d239-4ee0-a513-8c30ec4f1498)

 - Запуск с помощью триггера (немедленное выполнение) airflow dags trigger ml_pipeline
![image](https://github.com/user-attachments/assets/7e7d9a00-0081-426d-ba4f-305d5a2a4492)

- Проверка статуса выполнения airflow dags list-runs --dag-id ml_pipeline (свежие запуски = верхние записи)
![image](https://github.com/user-attachments/assets/490669f4-b066-4c9f-8fe9-c63d502547de)

- Запуск через веб-сервер airflow webserver -p 8080
После этого в браузере надо перейти по ссылке http://localhost:8080, в раздел DAGs и запустить DAG вручную.

# Анализ ошибок и устойчивости
Загрузка данных (load_data)
  1) Не указан путь к данным → для этого реализована проверка пути к файлу.
![image](https://github.com/user-attachments/assets/4e21f9b2-e4e7-4686-b4f2-516451c3eb4e)
  2) Неверный формат данных → логирование ошибки загрузки.

Предобработка (preprocessing_data)
  1) NaN или некорректные данные → удаление NaN значений и логировние с предупреждением.

Обучение модели (train_model)
  1) Модель не обучается (мало данных) → проверка размерности и логирование.

Оценка модели (evaluate_model)
  1) y_test имеет неверный формат → конвертация словаря в DataFrame (y_test_dict = json.loads(y_test_json) y_test = pd.DataFrame(list(y_test_dict.values()))).

Сохранение результатов (save_results)
  1) Ошибка при сохранении в локальное хранилище → try-except и логирование.
  2) Потеря соединения с Яндекс.Диском → повторные попытки с интервалом в минуту.

# Скриншоты работающего DAG:
load_data
![image](https://github.com/user-attachments/assets/d258e0b8-a320-4971-9dec-594a091caf70)

preproccessing_data
![image](https://github.com/user-attachments/assets/46d9013b-2cb4-4bdd-83f7-97eba1ef9a4f)

train_model
![image](https://github.com/user-attachments/assets/b1fae6ad-ee28-4b9e-82cc-67a894ceb20b)

evaluaate_model
![image](https://github.com/user-attachments/assets/177eb769-13c8-4a13-b85c-aee82cbbbb31)

save_results(без указания токена)
![image](https://github.com/user-attachments/assets/54858152-7eda-4ddb-a2e9-f656b3a3f5aa)

save_results(с токеном)
![image](https://github.com/user-attachments/assets/5f637cf6-b8f2-4f0f-aa96-3b2459b1a048)


