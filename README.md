# Exam_1
Экзамен Инжиниринг данных

# Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow и облачного хранилища для датасета Breast Cancer Wisconsin Diagnostic.
**Цель задания:** Спроектировать и реализовать автоматизированный ETL-процесс: от получения медицинских данных до выгрузки результатов модели в облачное хранилище с помощью Apache Airflow и Python. 

**Описание датасета:** датасет состоит из 32 колонок 
  1) Идентификационный номер
  2) Диагноз (М = злокачественный, В = доброкачественный)

(3-32) Для каждого ядра клетки вычисляются десять вещественных признаков:
  - радиус (среднее значение расстояний от центра до точек по периметру)
  - текстура (стандартное отклонение значений оттенков серого)
  - периметр
  - площадь
  - гладкость (локальное изменение длины радиуса)
  - компактность (периметр^2 / площадь - 1,0)
  - вогнутость (выраженность вогнутых участков контура)
  - вогнутые точки (количество вогнутых участков контура)
  - симметрия
  - фрактальная размерность ("приближение береговой линии" - 1)

Средняя, стандартная ошибка и «худшая» или наибольшая (среднее из трех наибольших значений) этих признаков были вычислены для каждого изображения, в результате чего получилось 30 признаков.

**ML-задача:** Разработать и обучить модель логистической регрессии, которая должна предсказывать, является опухоль злокачественной или доброкачественной на основе медицинских данных (задача бинарной классификации).

Пайплайн включает следующие этапы:
  - Загрузка данных - парсинг CSV
  - Предобработка - чистка, нормализация, обработка пропущенных значений
  - Обучение модели - разделение данных, обучение модели LogisticRegression на тренировочном наборе 
  - Оценка метрик - вычисление Accuracy, Precision, Recall, F1.
  - Сохранение результатов - модель и метрики выгружаются в облачное хранилище

![diagram](https://github.com/user-attachments/assets/74914ceb-d12f-4c7f-a77f-d44c07e9b9ae)

 
подробности архитектуры и схемы;

описание всех шагов пайплайна;

инструкции по запуску скриптов и DAG;

обоснование архитектурных решений;

описание интеграции с хранилищем (облачным или локальным);

анализ ошибок и устойчивости;

перечень идей/предложений для развития проекта;

скриншоты работающего дага.
