# Exam_1
Экзамен Инжиниринг данных

# Название проекта:
Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow и облачного хранилища для датасета Breast Cancer Wisconsin Diagnostic.

# Содержание:
1. Цель проекта и описание данных
2. Архитектура пайплайна
3. Скрипты пайплайна
4. DAG
5. Детали обработки данных
6. Инструкция по запуску
7. Описание интеграции с хранилищем
8. Анализ ошибок и устойчивости
9. Перечень идей и предложений для развития проекта
10. Скриншоты работающего дага

# Цель проекта и описание данных
**Цель задания:** Спроектировать и реализовать автоматизированный ETL-процесс: от получения медицинских данных до выгрузки результатов модели в облачное хранилище с помощью Apache Airflow и Python. 

**Описание датасета:** датасет состоит из 32 колонок (без пропусков) находится в папке /data.
  1) Идентификационный номер
  2) Диагноз (М = злокачественный, В = доброкачественный)

(3-32) Для каждого ядра клетки вычисляются десять вещественных признаков:
  - радиус (среднее значение расстояний от центра до точек по периметру)
  - текстура (стандартное отклонение значений оттенков серого)
  - периметр
  - площадь
  - гладкость (локальное изменение длины радиуса)
  - компактность (периметр^2 / площадь - 1,0)
  - вогнутость (выраженность вогнутых участков контура)
  - вогнутые точки (количество вогнутых участков контура)
  - симметрия
  - фрактальная размерность ("приближение береговой линии" - 1)

Средняя, стандартная ошибка и «худшая» или наибольшая (среднее из трех наибольших значений) этих признаков были вычислены для каждого изображения, в результате чего получилось 30 признаков.

**ML-задача:** Разработать и обучить модель логистической регрессии, которая должна предсказывать, является опухоль злокачественной или доброкачественной на основе медицинских данных (задача бинарной классификации).

# Архитектура пайплайна
Пайплайн включает следующие этапы:
  - Загрузка данных - парсинг CSV
  - Предобработка - чистка, нормализация, обработка пропущенных значений, перевод целевого значения в 0 и 1
  - Обучение модели - разделение данных, обучение модели LogisticRegression на тренировочном наборе 
  - Оценка метрик - вычисление Accuracy, Precision, Recall, F1.
  - Сохранение результатов - модель и метрики выгружаются в облачное хранилище

Визуацизация в виде блок-схемы:

![diagram](https://github.com/user-attachments/assets/74914ceb-d12f-4c7f-a77f-d44c07e9b9ae)

# Скрипты пайплайна
Все скрипты для пайплайна находятся в папке /etl.
Связи между скриптами
1. load_data.py
    - Загружает Breast Cancer Wisconsin Diagnostic Dataset из CSV-файла.
    - Выполняет базовый анализ: проверяет пропущенные значения, типы данных и статистику.
    - Сохраняет предварительно обработанные данные.
2. preprocess.py
    - Убирает ненужные колонки (`id`).
    - Заполняет пропущенные значения.
    - Нормализует данные.
    - Преобразует таргет в бинарный вид (1 - злокачественная опухоль, 0 - доброкаественная)
3. train_model.py
    - Делит на признаки и таргет
    - Делит на тренировочкую (80%) и тестовую (20%) выборки
    - Обучает LogisticRegression на обработанных данных.
4. evaluate.py
    - Вычисляет Accuracy, Precision, Recall, F1-score.
5. save_results.py
    - Сохраняет метрики в JSON и модель в Pickle в папку results.

Все скрипты запускаются из Airflow DAG последовательно

# DAG
Название DAG - pipeline_dag.py находится в папке /dags. Этот **Airflow DAG** реализует автоматизированный пайплайн для предобработки данных, обучения модели **Logistic Regression**, её оценки и сохранения результатов.


**Описание зависимостей:**


описание зависимостей между задачами (текстом);

**Инструкцию по запуску DAG:** (например, airflow tasks test task_id run_date).

# Инструкция по запуску
подробности архитектуры и схемы;

описание всех шагов пайплайна;

инструкции по запуску скриптов и DAG;

обоснование архитектурных решений;

описание интеграции с хранилищем (облачным или локальным);

анализ ошибок и устойчивости;

перечень идей/предложений для развития проекта;

скриншоты работающего дага.
